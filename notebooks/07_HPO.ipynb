{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Hiperparámetros en Redes Neuronales\n",
    "\n",
    "En este notebook abordaremos el tema de la Optimización de Hiperparámetros (HPO, por sus siglas en inglés: **Hyperparameter Optimization**) en redes neuronales. Para ello:\n",
    "\n",
    "1. Explicaremos qué es la optimización de hiperparámetros en detalle.\n",
    "2. Presentaremos un problema de HPO con una red neuronal tipo MLP sobre el dataset MNIST utilizando PyTorch.\n",
    "3. Desarrollaremos un ejemplo utilizando **Grid Search** (búsqueda en rejilla), explicando su funcionamiento y sus ventajas y desventajas.\n",
    "4. Realizaremos otro ejemplo con **Random Search** (búsqueda aleatoria).\n",
    "5. Presentaremos el concepto de **Optimización Bayesiana** y mostraremos un ejemplo práctico aplicando esta técnica al problema planteado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ¿Qué es la Optimización de Hiperparámetros?\n",
    "\n",
    "Cuando entrenamos una red neuronal, no sólo debemos preocuparnos por los parámetros aprendibles del modelo (los pesos y sesgos), sino también por aquellos parámetros que no se aprenden directamente a partir de los datos y deben definirse antes del entrenamiento: los **hiperparámetros**. Ejemplos de hiperparámetros incluyen:\n",
    "\n",
    "- La tasa de aprendizaje (learning rate) del optimizador.\n",
    "- El número de épocas.\n",
    "- Relacionados con la arquitectura de la red (número de capas, número de neuronas por capa).\n",
    "- El tamaño de batch.\n",
    "- Parámetros de regularización (dropout, L2, etc.).\n",
    "\n",
    "La optimización de hiperparámetros consiste en encontrar la combinación de estos que maximice el rendimiento del modelo en un conjunto de validación o a través de alguna métrica establecida.\n",
    "\n",
    "Matemáticamente, si consideramos un conjunto de hiperparámetros $ \\lambda = (\\lambda_1, \\lambda_2, ..., \\lambda_k) $, queremos resolver:\n",
    "\n",
    "$$\n",
    "\\lambda^* = \\underset{\\lambda \\in \\Lambda}{\\mathrm{argmax}}\\; f(\\lambda)\n",
    "$$\n",
    "\n",
    "donde $ f(\\lambda) $ es la función objetivo (típicamente el rendimiento del modelo en un conjunto de validación) y $ \\Lambda $ es el espacio de búsqueda de hiperparámetros.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problema de Ejemplo: MLP en MNIST con PyTorch\n",
    "\n",
    "Utilizaremos el dataset MNIST, un conjunto de datos muy conocido que contiene imágenes de dígitos escritos a mano (0 a 9). Entrenaremos una red neuronal MLP (Perceptrón Multicapa) sobre este dataset y buscaremos optimizar algunos hiperparámetros como:\n",
    "\n",
    "- La tasa de aprendizaje (learning rate)\n",
    "- El tamaño de batch (batch size)\n",
    "- El número de neuronas en la capa oculta\n",
    "\n",
    "Primero, construiremos la infraestructura básica: cargar el dataset, definir la red, la función de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones y configuración\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Para asegurarnos reproducibilidad\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Transformaciones de imágenes: normalización a 0.1307 y desviación estándar 0.3081 (valores estándar para MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Cargar datasets de entrenamiento y prueba\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Función que construye un MLP dado un número de neuronas en capa oculta y número de clases\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=128, num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def train_one_epoch(model, optimizer, criterion, dataloader, device='cpu'):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "def evaluate(model, criterion, dataloader, device='cpu'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "    return running_loss / total, 100. * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimización de Hiperparámetros con Grid Search\n",
    "\n",
    "La **Búsqueda en Rejilla (Grid Search)** consiste en definir un conjunto discreto y finito de valores posibles para cada hiperparámetro y luego entrenar el modelo para todas las combinaciones posibles. Al final, seleccionamos la combinación de hiperparámetros que mejor rendimiento haya obtenido.\n",
    "\n",
    "Por ejemplo, si queremos buscar sobre:\n",
    "\n",
    "- Learning rate: $\\{0.01, 0.001\\}$\n",
    "- Hidden size: $\\{64, 128\\}$\n",
    "- Batch size: $\\{64, 128\\}$\n",
    "\n",
    "Tendremos $2 \\times 2 \\times 2 = 8$ combinaciones a evaluar.\n",
    "\n",
    "La búsqueda en rejilla es simple de implementar y fácil de paralelizar, pero el costo computacional crece exponencialmente con el número de hiperparámetros y el número de valores por hiperparámetro. Además, no aprovecha información de corridas previas, simplemente explora todas las combinaciones.\n",
    "\n",
    "A continuación, mostraremos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para lr=0.1, hidden_size=64, batch_size=64:\n",
      "\tExactitud de entrenamiento: 98.11%\n",
      "\tExactitud de validación: 97.37%\n",
      "Resultados para lr=0.1, hidden_size=64, batch_size=128:\n",
      "\tExactitud de entrenamiento: 97.58%\n",
      "\tExactitud de validación: 97.16%\n",
      "Resultados para lr=0.1, hidden_size=128, batch_size=64:\n",
      "\tExactitud de entrenamiento: 98.59%\n",
      "\tExactitud de validación: 97.67%\n",
      "Resultados para lr=0.1, hidden_size=128, batch_size=128:\n",
      "\tExactitud de entrenamiento: 97.85%\n",
      "\tExactitud de validación: 97.15%\n",
      "Resultados para lr=0.01, hidden_size=64, batch_size=64:\n",
      "\tExactitud de entrenamiento: 93.94%\n",
      "\tExactitud de validación: 94.24%\n",
      "Resultados para lr=0.01, hidden_size=64, batch_size=128:\n",
      "\tExactitud de entrenamiento: 92.47%\n",
      "\tExactitud de validación: 93.11%\n",
      "Resultados para lr=0.01, hidden_size=128, batch_size=64:\n",
      "\tExactitud de entrenamiento: 94.21%\n",
      "\tExactitud de validación: 94.64%\n",
      "Resultados para lr=0.01, hidden_size=128, batch_size=128:\n",
      "\tExactitud de entrenamiento: 92.55%\n",
      "\tExactitud de validación: 93.09%\n",
      "Mejores parámetros encontrados con Grid Search: {'lr': 0.1, 'hidden_size': 128, 'batch_size': 64} con exactitud: 97.67\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de Grid Search\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [0.1, 0.01],\n",
    "    'hidden_size': [64, 128],\n",
    "    'batch_size': [64, 128]\n",
    "}\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "best_acc = 0.0\n",
    "best_params = None\n",
    "\n",
    "for lr, hidden_size, batch_size in product(param_grid['lr'], param_grid['hidden_size'], param_grid['batch_size']):\n",
    "    # Cargar datos con el batch_size actual\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = MLP(hidden_size=hidden_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
    "        val_loss, val_acc = evaluate(model, criterion, val_loader, device)\n",
    "\n",
    "    print(f'Resultados para lr={lr}, hidden_size={hidden_size}, batch_size={batch_size}:')\n",
    "    print(f'\\tExactitud de entrenamiento: {train_acc:.2f}%')\n",
    "    print(f'\\tExactitud de validación: {val_acc:.2f}%')\n",
    "        \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_params = {'lr': lr, 'hidden_size': hidden_size, 'batch_size': batch_size}\n",
    "\n",
    "print(\"Mejores parámetros encontrados con Grid Search:\", best_params, \"con exactitud:\", best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimización de Hiperparámetros con Random Search\n",
    "\n",
    "**Random Search** (Búsqueda Aleatoria) selecciona combinaciones aleatorias de hiperparámetros a partir de distribuciones definidas. A diferencia de la rejilla, no se explora exhaustivamente todo el espacio. Esto puede ser ventajoso cuando el espacio es muy grande, ya que se ha demostrado que la búsqueda aleatoria puede ser más eficiente que la rejilla en muchos casos, sobre todo cuando sólo unos pocos hiperparámetros influyen significativamente en el resultado.\n",
    "\n",
    "En términos matemáticos, si $\\lambda$ es un vector de hiperparámetros, la Búsqueda Aleatoria extrae $\\lambda$ de una distribución $ p(\\lambda) $ (por ejemplo, uniforme).\n",
    "\n",
    "$$\n",
    "\\lambda \\sim p(\\lambda)\n",
    "$$\n",
    "\n",
    "Luego se evalúa el rendimiento y se guarda el mejor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo vamos a usar listas con valores definidos a partir de las cuales escogemos valores al azar. Algo más complejo sería definir valores mínimo y máximo y escoger valores al azar entre medias, con una distribución uniforme, normal centrada en la media, log-normal para algunos hiperparámetros como la tasa de aprendizaje, etcétera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para lr=0.01, hidden_size=256, batch_size=64:\n",
      "\tExactitud de entrenamiento: 94.62%\n",
      "\tExactitud de validación: 94.82%\n",
      "Resultados para lr=0.001, hidden_size=128, batch_size=128:\n",
      "\tExactitud de entrenamiento: 85.89%\n",
      "\tExactitud de validación: 87.21%\n",
      "Resultados para lr=0.001, hidden_size=64, batch_size=64:\n",
      "\tExactitud de entrenamiento: 88.33%\n",
      "\tExactitud de validación: 89.11%\n",
      "Resultados para lr=0.0001, hidden_size=128, batch_size=32:\n",
      "\tExactitud de entrenamiento: 79.04%\n",
      "\tExactitud de validación: 80.68%\n",
      "Resultados para lr=0.001, hidden_size=64, batch_size=128:\n",
      "\tExactitud de entrenamiento: 85.78%\n",
      "\tExactitud de validación: 87.05%\n",
      "Mejores parámetros encontrados con Random Search: {'lr': 0.01, 'hidden_size': 256, 'batch_size': 64} con exactitud: 94.82\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Definir las distribuciones (podemos usar distribuciones simples)\n",
    "# Por ejemplo, lo más simple que podemos hacer es definir listas con posibles valores: \n",
    "lr_candidates = [0.1, 0.01, 0.001, 0.0001]\n",
    "hidden_size_candidates = [64, 128, 256]\n",
    "batch_size_candidates = [32, 64, 128]\n",
    "\n",
    "num_samples = 5  # Numero de combinaciones aleatorias a probar\n",
    "epochs = 5\n",
    "\n",
    "best_acc_random = 0.0\n",
    "best_params_random = None\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    lr = random.choice(lr_candidates)\n",
    "    hidden_size = random.choice(hidden_size_candidates)\n",
    "    batch_size = random.choice(batch_size_candidates)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = MLP(hidden_size=hidden_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
    "        val_loss, val_acc = evaluate(model, criterion, val_loader, device)\n",
    "\n",
    "    print(f'Resultados para lr={lr}, hidden_size={hidden_size}, batch_size={batch_size}:')\n",
    "    print(f'\\tExactitud de entrenamiento: {train_acc:.2f}%')\n",
    "    print(f'\\tExactitud de validación: {val_acc:.2f}%')\n",
    "        \n",
    "    if val_acc > best_acc_random:\n",
    "        best_acc_random = val_acc\n",
    "        best_params_random = {'lr': lr, 'hidden_size': hidden_size, 'batch_size': batch_size}\n",
    "\n",
    "print(\"Mejores parámetros encontrados con Random Search:\", best_params_random, \"con exactitud:\", best_acc_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimización Bayesiana\n",
    "\n",
    "La **Optimización Bayesiana** es un enfoque más sofisticado para la búsqueda de hiperparámetros. A diferencia de Grid Search o Random Search, la optimización bayesiana utiliza información de las evaluaciones previas del modelo para guiar la búsqueda hacia regiones más prometedoras del espacio de hiperparámetros.\n",
    "\n",
    "La idea principal es modelar la función objetivo $ f(\\lambda) $ a través de un modelo probabilístico (por ejemplo, un Proceso Gaussiano). Conforme se evalúan distintos hiperparámetros, este modelo probabilístico se actualiza, mejorando su aproximación de $ f(\\lambda) $. Luego se aplica una **función de adquisición** que sugiere el siguiente punto (conjunto de hiperparámetros) a evaluar, balanceando la exploración y la explotación del espacio.\n",
    "\n",
    "Matemáticamente, el proceso se puede describir como:\n",
    "\n",
    "1. Asumimos un prior sobre la función objetivo $ f(\\lambda) $, típicamente un proceso gaussiano $ f(\\lambda) \\sim GP(m(\\lambda), k(\\lambda,\\lambda')) $.\n",
    "2. Evaluamos la función en unos pocos puntos y actualizamos el posterior del GP.\n",
    "3. Elegimos el próximo punto a evaluar maximizando una función de adquisición $ a(\\lambda) $ (por ejemplo: Expected Improvement, UCB, etc.):\n",
    "$$\n",
    "\\lambda_{n+1} = \\underset{\\lambda \\in \\Lambda}{\\mathrm{argmax}} \\; a(\\lambda)\n",
    "$$\n",
    "4. Repetimos el proceso hasta converger o agotar recursos.\n",
    "\n",
    "Para este ejemplo utilizaremos la librería `hyperopt` para implementar una búsqueda bayesiana sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para lr=0.5566060853839194, hidden_size=128, batch_size=32:\n",
      "\tExactitud de entrenamiento: 93.44%                   \n",
      "\tExactitud de validación: 92.96%                      \n",
      "Resultados para lr=0.023028410254015495, hidden_size=64, batch_size=64:\n",
      "\tExactitud de entrenamiento: 95.98%                                 \n",
      "\tExactitud de validación: 95.90%                                    \n",
      "Resultados para lr=0.036661069573523226, hidden_size=128, batch_size=128:\n",
      "\tExactitud de entrenamiento: 96.03%                                \n",
      "\tExactitud de validación: 96.25%                                   \n",
      "Resultados para lr=0.12833572792811745, hidden_size=128, batch_size=64:\n",
      "\tExactitud de entrenamiento: 98.76%                                 \n",
      "\tExactitud de validación: 97.41%                                    \n",
      "Resultados para lr=0.153444193767084, hidden_size=64, batch_size=64:\n",
      "\tExactitud de entrenamiento: 98.26%                                 \n",
      "\tExactitud de validación: 97.28%                                    \n",
      "Resultados para lr=0.37229721951046907, hidden_size=128, batch_size=32:\n",
      "\tExactitud de entrenamiento: 96.81%                                 \n",
      "\tExactitud de validación: 95.77%                                    \n",
      "Resultados para lr=0.021401822702709287, hidden_size=128, batch_size=128:\n",
      "\tExactitud de entrenamiento: 94.60%                                 \n",
      "\tExactitud de validación: 94.87%                                    \n",
      "Resultados para lr=0.013960725564871544, hidden_size=128, batch_size=32:\n",
      "\tExactitud de entrenamiento: 96.89%                                 \n",
      "\tExactitud de validación: 96.83%                                    \n",
      "Resultados para lr=0.01133876196915736, hidden_size=128, batch_size=32:\n",
      "\tExactitud de entrenamiento: 96.60%                                 \n",
      "\tExactitud de validación: 96.65%                                    \n",
      "Resultados para lr=0.2609343724513239, hidden_size=128, batch_size=32:\n",
      "\tExactitud de entrenamiento: 98.11%                                 \n",
      "\tExactitud de validación: 96.72%                                    \n",
      "100%|██████████| 10/10 [10:19<00:00, 61.97s/trial, best loss: -97.41]\n",
      "Mejores hiperparámetros encontrados (Bayesiano): {'batch_size': 1, 'hidden_size': 1, 'lr': 0.12833572792811745}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# Función objetivo que recibe un diccionario con los hiperparámetros y devuelve la métrica y un status OK, necesario para hyperopt\n",
    "def objective(params):\n",
    "    lr = params['lr']\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = 5\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = MLP(hidden_size=hidden_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
    "        val_loss, val_acc = evaluate(model, criterion, val_loader, device)\n",
    "\n",
    "    print(f'Resultados para lr={lr}, hidden_size={hidden_size}, batch_size={batch_size}:')\n",
    "    print(f'\\tExactitud de entrenamiento: {train_acc:.2f}%')\n",
    "    print(f'\\tExactitud de validación: {val_acc:.2f}%')\n",
    "\n",
    "    # Queremos maximizar val_acc, pero hyperopt minimiza. Usamos -val_acc.\n",
    "    return {'loss': -val_acc, 'status': STATUS_OK}\n",
    "\n",
    "# Espacio de búsqueda\n",
    "space = {\n",
    "    'lr': hp.loguniform('lr', -5, 0),          # entre ~0.0067 y 1.0\n",
    "    'hidden_size': hp.choice('hidden_size', [64, 128, 256]),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128])\n",
    "}\n",
    "\n",
    "# Trials: Para guardar los resultados de cada iteración\n",
    "trials = Trials()\n",
    "\n",
    "# tpe: Tree of Parzen Estimators, una librería de optimización bayesiana\n",
    "# algo: suggest, un algoritmo que sugiere los siguientes hiperparámetros a probar\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "print(\"Mejores hiperparámetros encontrados (Bayesiano):\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Hemos visto diferentes enfoques para la optimización de hiperparámetros:\n",
    "\n",
    "- **Grid Search**: Exhaustivo y fácil, pero caro computacionalmente y no escalable.\n",
    "- **Random Search**: Más eficiente y escalable que Grid Search, puede encontrar buenas soluciones más rápido.\n",
    "- **Optimización Bayesiana**: Utiliza información de las evaluaciones previas para guiar la búsqueda, suele ser más eficiente en problemas complejos.\n",
    "\n",
    "Dependiendo de los recursos disponibles y la complejidad del problema, se puede elegir una u otra estrategia. En problemas del mundo real con muchos hiperparámetros, la optimización bayesiana es a menudo la más eficiente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

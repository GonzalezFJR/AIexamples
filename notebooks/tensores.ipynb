{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a los Tensores\n",
    "\n",
    "Los **tensores** son una generalización de los escalares (0D), vectores (1D) y matrices (2D) a dimensiones superiores. En el contexto de las matemáticas y la ciencia de datos, los tensores son estructuras de datos multidimensionales que pueden representar datos complejos y relaciones entre ellos.\n",
    "\n",
    "## ¿Qué es un Tensor?\n",
    "\n",
    "Matemáticamente, un tensor es un objeto que es invariantemente definido bajo transformaciones lineales. Sin embargo, en el contexto de programación y ciencia de datos, un tensor es simplemente una matriz multidimensional.\n",
    "\n",
    "- **Escalar**: Un solo número (tensor de orden 0).\n",
    "- **Vector**: Una lista de números (tensor de orden 1).\n",
    "- **Matriz**: Una cuadrícula de números (tensor de orden 2).\n",
    "- **Tensor de orden N**: Una estructura de datos N-dimensional.\n",
    "\n",
    "Por ejemplo, una imagen en color puede ser representada como un tensor de orden 3 con dimensiones (altura, anchura, canales de color).\n",
    "\n",
    "## Notación Matemática\n",
    "\n",
    "Un tensor de orden $ n $ en un espacio $ \\mathbb{R}^{I_1 \\times I_2 \\times \\dots \\times I_n} $ puede ser representado como:\n",
    "\n",
    "$$\n",
    "\\mathcal{T} \\in \\mathbb{R}^{I_1 \\times I_2 \\times \\dots \\times I_n}\n",
    "$$\n",
    "\n",
    "Donde $ I_k $ es la dimensión en el eje $ k $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones Matemáticas con Tensores\n",
    "\n",
    "Antes de pasar a la creación de tensores en NumPy, introducimos algunas de las operaciones matemáticas más comunes con tensores:\n",
    "\n",
    "### Producto Escalar para Vectores\n",
    "\n",
    "El **producto escalar** (o producto punto) de dos vectores $ \\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n $ se define como:\n",
    "\n",
    "$$\n",
    "\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^n a_i b_i\n",
    "$$\n",
    "\n",
    "Donde $ a_i $ y $ b_i $ son los elementos de los vectores $ \\mathbf{a} $ y $ \\mathbf{b} $, respectivamente.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Sea $\\mathbf{a} = [1, 2, 3, 4]$ y $\\mathbf{b} = [5, 6, 7, 8]$, entonces el producto escalar es:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{a} \\cdot \\mathbf{b} &= a_1 b_1 + a_2 b_2 + a_3 b_3 + a_4 b_4 \\\\\n",
    "&= (1)(5) + (2)(6) + (3)(7) + (4)(8) \\\\\n",
    "&= 5 + 12 + 21 + 32 \\\\\n",
    "&= 70\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Por lo tanto, $\\mathbf{a} \\cdot \\mathbf{b} = 70$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El producto escalar de a y b es: 70\n"
     ]
    }
   ],
   "source": [
    "### Ejemplo con python usando numpy\n",
    "import numpy as np\n",
    "\n",
    "# Definir los vectores\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "\n",
    "# Calcular el producto escalar\n",
    "producto_escalar = np.dot(a, b)\n",
    "\n",
    "print(\"El producto escalar de a y b es:\", producto_escalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicación de Matrices\n",
    "\n",
    "La **multiplicación de matrices** entre dos matrices $ A \\in \\mathbb{R}^{m \\times n} $ y $ B \\in \\mathbb{R}^{n \\times p} $ se define como:\n",
    "\n",
    "$$\n",
    "(AB)_{ij} = \\sum_{k=1}^n A_{ik} B_{kj}\n",
    "$$\n",
    "\n",
    "Donde el elemento resultante $ (AB)_{ij} $ es la suma de los productos de los elementos de la fila $ i $ de la matriz $ A $ y la columna $ j $ de la matriz $ B $.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Sea $A$ una matriz de dimensión $2 \\times 3$ y $B$ una matriz de dimensión $3 \\times 2$:\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "\\end{pmatrix}, \\quad\n",
    "B = \\begin{pmatrix}\n",
    "7 & 8 \\\\\n",
    "9 & 10 \\\\\n",
    "11 & 12 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "El producto $AB$ es una matriz de dimensión $2 \\times 2$, donde:\n",
    "\n",
    "$$\n",
    "(AB)_{ij} = \\sum_{k=1}^3 A_{ik} B_{kj}\n",
    "$$\n",
    "\n",
    "Calculamos cada elemento:\n",
    "\n",
    "1. $(AB)_{11}$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(AB)_{11} &= A_{11} B_{11} + A_{12} B_{21} + A_{13} B_{31} \\\\\n",
    "&= (1)(7) + (2)(9) + (3)(11) \\\\\n",
    "&= 7 + 18 + 33 = 58\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "2. $(AB)_{12}$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(AB)_{12} &= A_{11} B_{12} + A_{12} B_{22} + A_{13} B_{32} \\\\\n",
    "&= (1)(8) + (2)(10) + (3)(12) \\\\\n",
    "&= 8 + 20 + 36 = 64\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "3. $(AB)_{21}$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(AB)_{21} &= A_{21} B_{11} + A_{22} B_{21} + A_{23} B_{31} \\\\\n",
    "&= (4)(7) + (5)(9) + (6)(11) \\\\\n",
    "&= 28 + 45 + 66 = 139\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "4. $(AB)_{22}$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(AB)_{22} &= A_{21} B_{12} + A_{22} B_{22} + A_{23} B_{32} \\\\\n",
    "&= (4)(8) + (5)(10) + (6)(12) \\\\\n",
    "&= 32 + 50 + 72 = 154\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Entonces, el resultado de la multiplicación es:\n",
    "\n",
    "$$\n",
    "AB = \\begin{pmatrix}\n",
    "58 & 64 \\\\\n",
    "139 & 154 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado de la multiplicación AB es:\n",
      "[[ 58  64]\n",
      " [139 154]]\n"
     ]
    }
   ],
   "source": [
    "# Definir las matrices\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "\n",
    "B = np.array([[7, 8],\n",
    "              [9, 10],\n",
    "              [11, 12]])\n",
    "\n",
    "# Multiplicar las matrices\n",
    "AB = np.dot(A, B)\n",
    "\n",
    "print(\"El resultado de la multiplicación AB es:\")\n",
    "print(AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Multiplicación de Tensores de Mayor Dimensión\n",
    "\n",
    "Para tensores de mayor dimensión, la multiplicación se puede generalizar mediante el uso de la **contracción de índices**, donde se realiza la suma sobre ciertos ejes comunes entre los tensores involucrados.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Consideremos dos tensores de orden 3, $\\mathcal{A} \\in \\mathbb{R}^{I \\times J \\times K}$ y $\\mathcal{B} \\in \\mathbb{R}^{K \\times L \\times M}$. Podemos definir una operación de multiplicación sobre el índice $K$:\n",
    "\n",
    "$$\n",
    "\\mathcal{C}_{i j l m} = \\sum_{k=1}^K \\mathcal{A}_{i j k} \\mathcal{B}_{k l m}\n",
    "$$\n",
    "\n",
    "Esta operación resulta en un tensor $\\mathcal{C} \\in \\mathbb{R}^{I \\times J \\times L \\times M}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del tensor resultante C: (2, 2, 2, 2)\n",
      "Tensor resultante C:\n",
      "[[[[22 15]\n",
      "   [36 28]]\n",
      "\n",
      "  [[11  8]\n",
      "   [20 15]]]\n",
      "\n",
      "\n",
      " [[[ 9 14]\n",
      "   [20 13]]\n",
      "\n",
      "  [[20 21]\n",
      "   [36 26]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir los tensores\n",
    "A = np.random.randint(1, 5, size=(2, 2, 3))\n",
    "B = np.random.randint(1, 5, size=(3, 2, 2))\n",
    "\n",
    "# Realizar la multiplicación sobre el índice compartido\n",
    "C = np.tensordot(A, B, axes=([2], [0]))\n",
    "\n",
    "print(\"Forma del tensor resultante C:\", C.shape)\n",
    "print(\"Tensor resultante C:\")\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Suma Elemento a Elemento\n",
    "\n",
    "La **suma elemento a elemento** (también llamada suma Hadamard) de dos tensores $ \\mathcal{A}, \\mathcal{B} $ de la misma forma se define como:\n",
    "\n",
    "$$\n",
    "(\\mathcal{A} + \\mathcal{B})_{i_1, i_2, \\dots, i_n} = \\mathcal{A}_{i_1, i_2, \\dots, i_n} + \\mathcal{B}_{i_1, i_2, \\dots, i_n}\n",
    "$$\n",
    "\n",
    "Cada elemento del tensor resultante es la suma de los elementos correspondientes de $ \\mathcal{A} $ y $ \\mathcal{B} $.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Sea $\\mathcal{A}$ y $\\mathcal{B}$ matrices de dimensión $2 \\times 2$:\n",
    "\n",
    "$$\n",
    "\\mathcal{A} = \\begin{pmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "\\end{pmatrix}, \\quad\n",
    "\\mathcal{B} = \\begin{pmatrix}\n",
    "5 & 6 \\\\\n",
    "7 & 8 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "La suma elemento a elemento es:\n",
    "\n",
    "$$\n",
    "\\mathcal{A} + \\mathcal{B} = \\begin{pmatrix}\n",
    "1+5 & 2+6 \\\\\n",
    "3+7 & 4+8 \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "6 & 8 \\\\\n",
    "10 & 12 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma elemento a elemento de A y B es:\n",
      "[[ 6  8]\n",
      " [10 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir las matrices\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "\n",
    "# Sumar elemento a elemento\n",
    "suma = A + B\n",
    "\n",
    "print(\"La suma elemento a elemento de A y B es:\")\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Multiplicación Elemento a Elemento\n",
    "\n",
    "La **multiplicación elemento a elemento** (también llamada producto Hadamard) de dos tensores $ \\mathcal{A}, \\mathcal{B} $ de la misma forma se define como:\n",
    "\n",
    "$$\n",
    "(\\mathcal{A} \\circ \\mathcal{B})_{i_1, i_2, \\dots, i_n} = \\mathcal{A}_{i_1, i_2, \\dots, i_n} \\cdot \\mathcal{B}_{i_1, i_2, \\dots, i_n}\n",
    "$$\n",
    "\n",
    "Cada elemento del tensor resultante es el producto de los elementos correspondientes de $ \\mathcal{A} $ y $ \\mathcal{B} $.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Utilizando las mismas matrices $\\mathcal{A}$ y $\\mathcal{B}$ del ejemplo anterior:\n",
    "\n",
    "$$\n",
    "\\mathcal{A} \\circ \\mathcal{B} = \\begin{pmatrix}\n",
    "1 \\times 5 & 2 \\times 6 \\\\\n",
    "3 \\times 7 & 4 \\times 8 \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "5 & 12 \\\\\n",
    "21 & 32 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El producto elemento a elemento de A y B es:\n",
      "[[ 5 12]\n",
      " [21 32]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir las matrices\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "\n",
    "# Multiplicar elemento a elemento\n",
    "producto_hadamard = A * B\n",
    "\n",
    "print(\"El producto elemento a elemento de A y B es:\")\n",
    "print(producto_hadamard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de frameworks para trabajar con tensores: tensorflow y pytorch\n",
    "\n",
    "En el mundo del aprendizaje automático y el procesamiento de datos a gran escala, TensorFlow y PyTorch son dos de los frameworks más populares y ampliamente utilizados. Ambos están diseñados para trabajar con tensores y facilitan la implementación de modelos de aprendizaje profundo.\n",
    "\n",
    "### ¿Qué son TensorFlow y PyTorch?\n",
    "\n",
    "- TensorFlow: Desarrollado por Google Brain, TensorFlow es una biblioteca de código abierto para computación numérica y aprendizaje automático. Permite a los desarrolladores crear gráficos de flujo de datos, donde los nodos representan operaciones matemáticas y las aristas representan los datos multidimensionales (tensores) que fluyen entre ellos.\n",
    "\n",
    "- PyTorch: Desarrollado por Facebook's AI Research lab (FAIR), PyTorch es otra biblioteca de código abierto que proporciona herramientas para construir y entrenar redes neuronales. A diferencia de TensorFlow, que originalmente utilizaba gráficos estáticos, PyTorch se basa en gráficos dinámicos, lo que facilita la construcción y modificación de modelos en tiempo real.\n",
    "\n",
    "### ¿Por qué son necesarios?\n",
    "\n",
    "Estos frameworks simplifican muchas de las tareas complejas involucradas en el desarrollo de modelos de aprendizaje profundo:\n",
    "\n",
    "- Abstracción: Proporcionan una capa de abstracción sobre las operaciones matemáticas complejas, permitiendo a los desarrolladores centrarse en el diseño del modelo en lugar de en los detalles de implementación.\n",
    "\n",
    "- Eficiencia: Optimizan automáticamente las operaciones matemáticas para aprovechar al máximo el hardware disponible, como CPUs y GPUs.\n",
    "\n",
    "- Comunidad y Soporte: Ambos tienen una gran comunidad de desarrolladores y una amplia gama de recursos, tutoriales y ejemplos.\n",
    "\n",
    "### Importancia de la Ejecución en GPU\n",
    "\n",
    "Las GPUs (Unidades de Procesamiento Gráfico) están diseñadas para realizar cálculos en paralelo a alta velocidad, lo que es ideal para las operaciones matriciales y tensoriales intensivas en cómputo que se encuentran en el aprendizaje profundo.\n",
    "\n",
    "- Aceleración: Ejecutar modelos en GPUs puede acelerar significativamente el entrenamiento y la inferencia.\n",
    "\n",
    "- Escalabilidad: Permite manejar grandes volúmenes de datos y modelos más complejos.\n",
    "\n",
    "- Optimización: Tanto TensorFlow como PyTorch proporcionan soporte integrado para ejecutar operaciones en GPUs, optimizando el rendimiento sin necesidad de ajustes manuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de operaciones tensoriales con Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El producto escalar de a y b es: 70.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Producto escalar\n",
    "\n",
    "# Definir los vectores\n",
    "a = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "b = tf.constant([5, 6, 7, 8], dtype=tf.float32)\n",
    "\n",
    "# Calcular el producto escalar\n",
    "producto_escalar = tf.tensordot(a, b, axes=1)\n",
    "\n",
    "print(\"El producto escalar de a y b es:\", producto_escalar.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado de la multiplicación AB es:\n",
      "[[ 58.  64.]\n",
      " [139. 154.]]\n"
     ]
    }
   ],
   "source": [
    "# Multiplicación de matrices\n",
    "\n",
    "# Definir las matrices\n",
    "A = tf.constant([[1, 2, 3],\n",
    "                 [4, 5, 6]], dtype=tf.float32)\n",
    "\n",
    "B = tf.constant([[7, 8],\n",
    "                 [9, 10],\n",
    "                 [11, 12]], dtype=tf.float32)\n",
    "\n",
    "# Multiplicar las matrices\n",
    "AB = tf.matmul(A, B)\n",
    "\n",
    "print(\"El resultado de la multiplicación AB es:\")\n",
    "print(AB.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del tensor resultante C: (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Multiplicación de tensores de más dimensión\n",
    "\n",
    "# Definir los tensores\n",
    "A = tf.random.uniform(shape=(2, 2, 3), minval=1, maxval=5, dtype=tf.int32)\n",
    "B = tf.random.uniform(shape=(3, 2, 2), minval=1, maxval=5, dtype=tf.int32)\n",
    "\n",
    "# Realizar la multiplicación sobre el índice compartido\n",
    "C = tf.tensordot(A, B, axes=([2], [0]))\n",
    "\n",
    "print(\"Forma del tensor resultante C:\", C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma elemento a elemento de A y B es:\n",
      "[[ 6.  8.]\n",
      " [10. 12.]]\n",
      "El producto elemento a elemento de A y B es:\n",
      "[[ 5. 12.]\n",
      " [21. 32.]]\n"
     ]
    }
   ],
   "source": [
    "# Suma elemento a elemento\n",
    "\n",
    "# Definir las matrices\n",
    "A = tf.constant([[1, 2],\n",
    "                 [3, 4]], dtype=tf.float32)\n",
    "\n",
    "B = tf.constant([[5, 6],\n",
    "                 [7, 8]], dtype=tf.float32)\n",
    "\n",
    "# Sumar elemento a elemento\n",
    "suma = tf.add(A, B)\n",
    "\n",
    "print(\"La suma elemento a elemento de A y B es:\")\n",
    "print(suma.numpy())\n",
    "\n",
    "# Multiplicación elemento a elemento\n",
    "# Definir las matrices\n",
    "A = tf.constant([[1, 2],\n",
    "                 [3, 4]], dtype=tf.float32)\n",
    "\n",
    "B = tf.constant([[5, 6],\n",
    "                 [7, 8]], dtype=tf.float32)\n",
    "\n",
    "# Multiplicar elemento a elemento\n",
    "producto_hadamard = tf.multiply(A, B)\n",
    "\n",
    "print(\"El producto elemento a elemento de A y B es:\")\n",
    "print(producto_hadamard.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de operaciones tensoriales con pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El producto escalar de a y b es: 70.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Producto escalar\n",
    "\n",
    "# Definir los vectores\n",
    "a = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "b = torch.tensor([5, 6, 7, 8], dtype=torch.float32)\n",
    "\n",
    "# Calcular el producto escalar\n",
    "producto_escalar = torch.dot(a, b)\n",
    "\n",
    "print(\"El producto escalar de a y b es:\", producto_escalar.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado de la multiplicación AB es:\n",
      "tensor([[ 58.,  64.],\n",
      "        [139., 154.]])\n"
     ]
    }
   ],
   "source": [
    "# Multiplicación de matrices\n",
    "\n",
    "# Definir las matrices\n",
    "A = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "B = torch.tensor([[7, 8],\n",
    "                  [9, 10],\n",
    "                  [11, 12]], dtype=torch.float32)\n",
    "\n",
    "# Multiplicar las matrices\n",
    "AB = torch.matmul(A, B)\n",
    "\n",
    "print(\"El resultado de la multiplicación AB es:\")\n",
    "print(AB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del tensor resultante C: torch.Size([2, 2, 2, 2])\n",
      "Tensor resultante C:\n",
      "tensor([[[[10, 13],\n",
      "          [26, 18]],\n",
      "\n",
      "         [[17, 17],\n",
      "          [30, 23]]],\n",
      "\n",
      "\n",
      "        [[[18, 17],\n",
      "          [32, 22]],\n",
      "\n",
      "         [[20, 21],\n",
      "          [40, 28]]]])\n"
     ]
    }
   ],
   "source": [
    "# Multiplicación de tensores de más dimensión\n",
    "\n",
    "# Definir los tensores\n",
    "A = torch.randint(1, 5, (2, 2, 3))\n",
    "B = torch.randint(1, 5, (3, 2, 2))\n",
    "\n",
    "# Realizar la multiplicación sobre el índice compartido\n",
    "C = torch.tensordot(A, B, dims=([2], [0]))\n",
    "\n",
    "print(\"Forma del tensor resultante C:\", C.shape)\n",
    "print(\"Tensor resultante C:\")\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma elemento a elemento de A y B es:\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "El producto elemento a elemento de A y B es:\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n"
     ]
    }
   ],
   "source": [
    "# Suma elemento a elemento\n",
    "\n",
    "# Definir las matrices\n",
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]], dtype=torch.float32)\n",
    "\n",
    "B = torch.tensor([[5, 6],\n",
    "                  [7, 8]], dtype=torch.float32)\n",
    "\n",
    "# Sumar elemento a elemento\n",
    "suma = torch.add(A, B)\n",
    "\n",
    "print(\"La suma elemento a elemento de A y B es:\")\n",
    "print(suma)\n",
    "\n",
    "# Multiplicación elemento a elemento\n",
    "# Definir las matrices\n",
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]], dtype=torch.float32)\n",
    "\n",
    "B = torch.tensor([[5, 6],\n",
    "                  [7, 8]], dtype=torch.float32)\n",
    "\n",
    "# Multiplicar elemento a elemento\n",
    "producto_hadamard = A * B\n",
    "\n",
    "print(\"El producto elemento a elemento de A y B es:\")\n",
    "print(producto_hadamard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de GPU para realizar operaciones tensoriales\n",
    "\n",
    "Las GPUs (Unidades de Procesamiento Gráfico) son dispositivos altamente paralelos diseñados originalmente para manejar cálculos gráficos intensivos. En el contexto del aprendizaje profundo y las operaciones tensoriales, las GPUs ofrecen ventajas significativas sobre las CPUs:\n",
    "\n",
    "- Paralelización: Las GPUs contienen miles de núcleos que pueden ejecutar miles de hilos simultáneamente, lo que permite procesar grandes cantidades de datos en paralelo.\n",
    "- Ancho de Banda de Memoria: Las GPUs tienen un ancho de banda de memoria mucho mayor que las CPUs, lo que facilita la transferencia rápida de datos.\n",
    "- Optimización para Cálculos Matriciales: Las arquitecturas de GPU están optimizadas para operaciones matriciales y vectoriales, que son fundamentales en el aprendizaje profundo.\n",
    "\n",
    "Los frameworks como TensorFlow y PyTorch están diseñados para aprovechar estas capacidades, permitiendo que las operaciones tensoriales se ejecuten en GPUs con mínima intervención del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de uso de TensorFlow en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: []\n",
      "Operaciones realizadas en GPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verificar si hay una GPU disponible\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Definir los tensores en el contexto de la GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    # Crear tensores aleatorios grandes\n",
    "    A = tf.random.uniform([1000, 1000], minval=0, maxval=1)\n",
    "    B = tf.random.uniform([1000, 1000], minval=0, maxval=1)\n",
    "\n",
    "    # Realizar una multiplicación de matrices\n",
    "    C = tf.matmul(A, B)\n",
    "\n",
    "    # Realizar una suma elemento a elemento\n",
    "    D = tf.add(A, B)\n",
    "\n",
    "    # Calcular el producto elemento a elemento\n",
    "    E = tf.multiply(A, B)\n",
    "\n",
    "# Ejecutar y obtener los resultados\n",
    "print(\"Operaciones realizadas en GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de uso de pyTorch en GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda\n",
      "Operaciones realizadas en cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Verificar si hay una GPU disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Dispositivo utilizado:\", device)\n",
    "\n",
    "# Crear tensores aleatorios grandes y moverlos al dispositivo (GPU o CPU)\n",
    "A = torch.rand(1000, 1000, device=device)\n",
    "B = torch.rand(1000, 1000, device=device)\n",
    "\n",
    "# Realizar una multiplicación de matrices\n",
    "C = torch.matmul(A, B)\n",
    "\n",
    "# Realizar una suma elemento a elemento\n",
    "D = torch.add(A, B)\n",
    "\n",
    "# Calcular el producto elemento a elemento\n",
    "E = torch.mul(A, B)\n",
    "\n",
    "print(\"Operaciones realizadas en\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de cpu vs gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Tiempo en CPU: 15.7036 segundos\n",
      "Tiempo en GPU: 1.2756 segundos\n",
      "La GPU fue 12.31 veces más rápida que la CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Determinar si hay una GPU disponible\n",
    "device_cpu = torch.device('cpu')\n",
    "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Definir una función para medir el tiempo de ejecución\n",
    "def benchmark(device, size=10000):\n",
    "    # Crear tensores aleatorios grandes en el dispositivo especificado\n",
    "    A = torch.rand(size, size, device=device)\n",
    "    B = torch.rand(size, size, device=device)\n",
    "\n",
    "    # Sincronizar antes de empezar la medición de tiempo\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Realizar operaciones tensoriales complejas\n",
    "    for _ in range(10):\n",
    "        C = torch.matmul(A, B)\n",
    "        D = torch.add(A, B)\n",
    "        E = torch.mul(A, B)\n",
    "        F = torch.sin(C)\n",
    "        G = torch.exp(D)\n",
    "\n",
    "    # Sincronizar nuevamente después de las operaciones\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Tamaño de los tensores\n",
    "tensor_size = 1024*8  # Ajusta este valor según la capacidad de tu hardware\n",
    "\n",
    "# Medir tiempo en CPU\n",
    "time_cpu = benchmark(device_cpu, size=tensor_size)\n",
    "print(f\"Tiempo en CPU: {time_cpu:.4f} segundos\")\n",
    "\n",
    "# Medir tiempo en GPU (si está disponible)\n",
    "if device_gpu.type == 'cuda':\n",
    "    time_gpu = benchmark(device_gpu, size=tensor_size)\n",
    "    print(f\"Tiempo en GPU: {time_gpu:.4f} segundos\")\n",
    "    print(f\"La GPU fue {time_cpu / time_gpu:.2f} veces más rápida que la CPU.\")\n",
    "else:\n",
    "    print(\"No hay GPU disponible para realizar la comparación.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
